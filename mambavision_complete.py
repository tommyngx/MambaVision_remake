# -*- coding: utf-8 -*-
"""MambaVision_Complete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fyLsxkEmx-PSALT0u4hlSOWgvJKWQy45

# MambaVision: A Hybrid Mamba-Transformer Vision Backbone

Implementare completÄƒ a modelului MambaVision inspirat din lucrarea "MambaVision: A Hybrid Mambaâ€‘Transformer Vision Backbone" ([arXiv:2407.08083](https://arxiv.org/abs/2407.08083)).

## Caracteristici:
- **Arhitectura MambaVision**: Model hibrid care combinÄƒ blocuri Mamba È™i Transformer
- **Dataset Sintetic**: FoloseÈ™te torchvision.datasets.FakeData pentru testare rapidÄƒ
- **Pipeline Complet de Antrenament**: Cu metrici, logging È™i salvare checkpoints
- **Integrare Wandb**: Pentru tracking experimente È™i vizualizare
- **VizualizÄƒri**: Diagrame arhitecturÄƒ È™i curbe de antrenament

## Structura Arhitecturii:
1. **Patch Embedding**: ConverteÈ™te imagini Ã®n secvenÈ›e de token-uri
2. **Blocuri Hibride**: AlterneazÄƒ layere Mamba È™i Transformer
3. **Classification Head**: Layer final pentru predicÈ›ii

## ğŸ“¦ 1. Import-uri È™i Setup
"""

"""
Simplified MambaVision Model Architecture
Inspired by "MambaVision: A Hybrid Mambaâ€‘Transformer Vision Backbone"
https://arxiv.org/abs/2407.08083
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
from typing import Optional, Dict, List, Tuple, Any

import numpy as np
import matplotlib.pyplot as plt
import time
import os
import argparse
from tqdm import tqdm
import wandb

# Set random seeds pentru reproducibilitate
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)
np.random.seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# Setup device
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ğŸš€ Using device: {device}")
if torch.cuda.is_available():
    print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ”¥ CUDA Version: {torch.version.cuda}")
    print(f"âš¡ PyTorch Version: {torch.__version__}")
else:
    print(f"ğŸ’» Running on CPU")
    print(f"âš¡ PyTorch Version: {torch.__version__}")

print("âœ… Setup complet!")

"""## ğŸ§  2. Implementarea MambaBlock

Blocul Mamba este componenta principalÄƒ care implementeazÄƒ conceptele de state space modeling pentru procesarea eficientÄƒ a secvenÈ›elor.

"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class MambaBlock(nn.Module):
    """
    Diagram-following Mamba block with training optimizations.
    Keeps the exact structure from the diagram but adds stability improvements.
    """
    def __init__(self, dim: int, state_size: int = 16, conv_kernel: int = 4):
        super().__init__()
        self.dim = dim
        self.state_size = state_size

        # 1. Linear projection at top (from diagram)
        self.in_proj = nn.Linear(dim, dim * 2)

        # 2. SSM component for left branch (simplified but real SSM)
        self.ssm_A = nn.Parameter(torch.randn(dim, state_size) * 0.01)  # Small init
        self.ssm_B = nn.Parameter(torch.randn(dim, state_size) * 0.01)
        self.ssm_C = nn.Parameter(torch.randn(dim, state_size) * 0.01)
        self.dt_proj = nn.Linear(dim, dim)

        # 3. Two Conv1D layers (as shown in diagram)
        self.conv1d_left = nn.Conv1d(
            in_channels=dim, out_channels=dim, 
            kernel_size=conv_kernel, padding='same', groups=dim
        )
        self.conv1d_right = nn.Conv1d(
            in_channels=dim, out_channels=dim,
            kernel_size=conv_kernel, padding='same', groups=dim  
        )

        # 4. Two Linear layers at bottom (as shown in diagram)
        self.linear_left = nn.Linear(dim, dim)
        self.linear_right = nn.Linear(dim, dim)

        # 5. Activation (Ïƒ in diagram)
        self.act = nn.SiLU()
        
        # STABILITY IMPROVEMENTS:
        self.dropout = nn.Dropout(0.1)  # Prevent overfitting
        self.layer_norm = nn.LayerNorm(dim)  # Stabilize training

    def simple_ssm(self, x):
        """Simplified SSM that's more trainable than the complex version"""
        B, L, D = x.shape
        
        # Simple state space operation (trainable approximation)
        dt = torch.sigmoid(self.dt_proj(x))  # Use sigmoid instead of softplus for stability
        
        # Simplified selective scan approximation
        # This is much simpler than real Mamba but keeps the concept
        state_input = torch.einsum('bld,ds->bls', x, self.ssm_B)
        state_output = torch.einsum('bls,ds->bld', state_input, self.ssm_C)
        
        # Apply temporal modulation (key SSM concept)
        output = state_output * dt
        
        return output

    def forward(self, x):
        """
        Forward pass following diagram structure exactly, with stability improvements.
        """
        B, L, D = x.shape
        residual = x  # CRUCIAL: Keep original for residual
        
        # Apply layer norm for stability (doesn't change structure)
        x = self.layer_norm(x)

        # STEP 1: Linear projection (top of diagram)
        x_proj = self.in_proj(x)  # (B, L, 2*D)
        
        # STEP 2: Split operation (C in diagram) 
        x_left, x_right = x_proj.split(self.dim, dim=-1)

        # LEFT BRANCH: SSM â†’ Ïƒ â†’ Conv1D â†’ Linear
        left = self.simple_ssm(x_left)  # SSM processing
        left = self.act(left)           # Ïƒ activation
        
        # Conv1D processing
        left = left.transpose(1, 2)     # (B, D, L) for conv1d
        left = self.conv1d_left(left)   # Conv1D
        left = left.transpose(1, 2)     # Back to (B, L, D)
        
        left = self.linear_left(left)   # Linear projection
        left = self.dropout(left)       # Stability

        # RIGHT BRANCH: Ïƒ â†’ Conv1D â†’ Linear
        right = self.act(x_right)       # Ïƒ activation
        
        # Conv1D processing
        right = right.transpose(1, 2)   # (B, D, L) for conv1d  
        right = self.conv1d_right(right) # Conv1D
        right = right.transpose(1, 2)   # Back to (B, L, D)
        
        right = self.linear_right(right) # Linear projection
        right = self.dropout(right)     # Stability

        # STEP 3: Element-wise multiplication (âŠ— in diagram)
        output = left * right

        # CRITICAL FOR TRAINING: Add residual connection
        # This is NOT in the diagram but essential for trainability
        output = output + residual
        
        return output

# Test the diagram-following MambaBlock
print("ğŸ“Š Testing Diagram-Following MambaBlock with Training Improvements...")
test_input = torch.randn(2, 196, 192)
test_mamba = MambaBlock(dim=192)
test_output = test_mamba(test_input)

print(f"âœ… Input:  {test_input.shape}")
print(f"âœ… Output: {test_output.shape}")
print(f"ğŸ“Š Parameters: {sum(p.numel() for p in test_mamba.parameters()):,}")

print("\nğŸ¯ Diagram Structure Preserved:")
print("âœ… Linear â†’ Split(C) â†’ [SSMâ†’Ïƒâ†’Conv1Dâ†’Linear] âŠ— [Ïƒâ†’Conv1Dâ†’Linear]")

print("\nğŸ› ï¸  Training Improvements Added:")
print("â€¢ LayerNorm for input stability")
print("â€¢ Dropout for regularization")  
print("â€¢ Simplified SSM (more trainable)")
print("â€¢ Small parameter initialization")
print("â€¢ Residual connection (CRITICAL)")
print("â€¢ Sigmoid instead of softplus in dt")

print("\nğŸ’¡ Training Tips:")
print("â€¢ Start with learning rate 1e-4")
print("â€¢ Use gradient clipping (max_norm=0.5)")
print("â€¢ Monitor gradients - should not vanish")
print("â€¢ If still poor, try reducing dropout to 0.05")

"""## ğŸ”„ 3. Implementarea TransformerBlock

Blocul Transformer standard pentru arhitectura hibridÄƒ, cu self-attention È™i MLP.

"""

class TransformerBlock(nn.Module):
    """
    Standard Transformer block for hybrid architecture
    """
    def __init__(self, dim: int, num_heads: int = 8, mlp_ratio: float = 4.0, dropout: float = 0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = nn.MultiheadAttention(
            embed_dim=dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm2 = nn.LayerNorm(dim)

        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = nn.Sequential(
            nn.Linear(dim, mlp_hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_hidden_dim, dim),
            nn.Dropout(dropout)
        )

    def forward(self, x):
        # Self-attention with residual connection
        x_norm = self.norm1(x)
        attn_out, _ = self.attn(x_norm, x_norm, x_norm)
        x = x + attn_out

        # MLP with residual connection
        x = x + self.mlp(self.norm2(x))

        return x

# Test TransformerBlock
print("ğŸ§ª Testing TransformerBlock...")
test_transformer = TransformerBlock(dim=192, num_heads=6)
test_input = torch.randn(2, 196, 192)
test_output = test_transformer(test_input)
print(f"âœ… TransformerBlock: Input {test_input.shape} -> Output {test_output.shape}")
print(f"ğŸ“Š TransformerBlock parameters: {sum(p.numel() for p in test_transformer.parameters()):,}")

"""## ğŸ–¼ï¸ 4. Implementarea PatchEmbed

ConverteÈ™te imaginile Ã®n patch-uri È™i le transformÄƒ Ã®n token-uri pentru procesare.

"""

class PatchEmbed(nn.Module):
    """
    Image to Patch Embedding
    """
    def __init__(self, img_size: int = 224, patch_size: int = 16, in_chans: int = 3, embed_dim: int = 768):
        super().__init__()
        self.img_size = img_size
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2

        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)

    def forward(self, x):
        B, C, H, W = x.shape
        x = self.proj(x)  # (B, embed_dim, H/patch_size, W/patch_size)
        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)
        return x

# Test PatchEmbed
print("ğŸ§ª Testing PatchEmbed...")
test_patch_embed = PatchEmbed(img_size=224, patch_size=16, embed_dim=192)
test_input = torch.randn(2, 3, 224, 224)  # (batch_size, channels, height, width)
test_output = test_patch_embed(test_input)
print(f"âœ… PatchEmbed: Input {test_input.shape} -> Output {test_output.shape}")
print(f"ğŸ“Š NumÄƒrul de patch-uri: {test_patch_embed.num_patches}")
print(f"ğŸ“Š PatchEmbed parameters: {sum(p.numel() for p in test_patch_embed.parameters()):,}")

"""## ğŸ—ï¸ 5. Modelul Principal MambaVision

Implementarea completÄƒ a modelului hibrid care combinÄƒ blocurile Mamba È™i Transformer.

"""

class MambaVision(nn.Module):
    """
    Simplified MambaVision: A Hybrid Mamba-Transformer Vision Backbone

    This implementation includes:
    - Patch embedding for converting images to tokens
    - Alternating Mamba and Transformer blocks
    - Classification head
    """
    def __init__(
        self,
        img_size: int = 224,
        patch_size: int = 16,
        in_chans: int = 3,
        num_classes: int = 1000,
        embed_dim: int = 768,
        depth: int = 12,
        num_heads: int = 12,
        mlp_ratio: float = 4.0,
        use_mamba_ratio: float = 0.5,  # Fraction of blocks that are Mamba vs Transformer
        dropout: float = 0.1,
        state_size: int = 16,
    ):
        super().__init__()
        self.num_classes = num_classes
        self.embed_dim = embed_dim
        self.depth = depth

        # Patch embedding
        self.patch_embed = PatchEmbed(
            img_size=img_size,
            patch_size=patch_size,
            in_chans=in_chans,
            embed_dim=embed_dim
        )

        # Positional embedding
        self.pos_embed = nn.Parameter(
            torch.zeros(1, self.patch_embed.num_patches, embed_dim)
        )
        self.pos_drop = nn.Dropout(dropout)

        # Hybrid blocks (alternating Mamba and Transformer)
        self.blocks = nn.ModuleList()
        num_mamba_blocks = int(depth * use_mamba_ratio)

        for i in range(depth):
            if i < num_mamba_blocks:
                # Use Mamba block
                block = MambaBlock(
                    dim=embed_dim,
                    state_size=state_size
                )
            else:
                # Use Transformer block
                block = TransformerBlock(
                    dim=embed_dim,
                    num_heads=num_heads,
                    mlp_ratio=mlp_ratio,
                    dropout=dropout
                )
            self.blocks.append(block)

        # Classification head
        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Linear(embed_dim, num_classes)

        # Initialize weights
        self._init_weights()

    def _init_weights(self):
        """Initialize weights"""
        # Initialize positional embeddings
        torch.nn.init.trunc_normal_(self.pos_embed, std=0.02)

        # Initialize other weights
        for m in self.modules():
            if isinstance(m, nn.Linear):
                torch.nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    torch.nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.LayerNorm):
                torch.nn.init.constant_(m.bias, 0)
                torch.nn.init.constant_(m.weight, 1.0)

    def forward_features(self, x):
        """Forward pass through feature extraction layers"""
        # Patch embedding
        x = self.patch_embed(x)  # (B, num_patches, embed_dim)

        # Add positional embedding
        x = x + self.pos_embed
        x = self.pos_drop(x)

        # Apply blocks
        for block in self.blocks:
            x = block(x)

        # Global average pooling
        x = self.norm(x)
        x = x.mean(dim=1)  # Global average pooling over sequence dimension

        return x

    def forward(self, x):
        """Forward pass"""
        x = self.forward_features(x)
        x = self.head(x)
        return x

def create_mambavision_tiny(num_classes: int = 10, img_size: int = 224) -> MambaVision:
    """Create a tiny MambaVision model for quick testing"""
    return MambaVision(
        img_size=img_size,
        patch_size=16,
        in_chans=3,
        num_classes=num_classes,
        embed_dim=192,
        depth=6,
        num_heads=6,
        use_mamba_ratio=0.5,
        dropout=0.1,
        state_size=16,
    )


def create_mambavision_small(num_classes: int = 10, img_size: int = 224) -> MambaVision:
    """Create a small MambaVision model"""
    return MambaVision(
        img_size=img_size,
        patch_size=16,
        in_chans=3,
        num_classes=num_classes,
        embed_dim=384,
        depth=8,
        num_heads=8,
        use_mamba_ratio=0.5,
        dropout=0.1,
        state_size=16,
    )

# Test model creation
print("ğŸ§ª Testing MambaVision models...")
model_tiny = create_mambavision_tiny(num_classes=10)
model_small = create_mambavision_small(num_classes=10)

total_params_tiny = sum(p.numel() for p in model_tiny.parameters())
total_params_small = sum(p.numel() for p in model_small.parameters())

print(f"âœ… Tiny model created!")
print(f"ğŸ“Š Tiny model parameters: {total_params_tiny:,}")
print(f"âœ… Small model created!")
print(f"ğŸ“Š Small model parameters: {total_params_small:,}")

# Test forward pass
test_input = torch.randn(2, 3, 224, 224)
with torch.no_grad():
    y_tiny = model_tiny(test_input)
    y_small = model_small(test_input)

print(f"\nğŸ” Forward pass test:")
print(f"Input shape: {test_input.shape}")
print(f"Tiny output shape: {y_tiny.shape}")
print(f"Small output shape: {y_small.shape}")
print("âœ… Model creation successful!")

"""## ğŸ“Š 6. UtilitÄƒÈ›ile pentru Dataset

Implementarea pentru crearea È™i gestionarea dataset-urilor sintetice folosind FakeData.

"""

def get_transforms(img_size: int = 224, augment: bool = True) -> Tuple[transforms.Compose, transforms.Compose]:
    """
    Get train and validation transforms

    Args:
        img_size: Target image size
        augment: Whether to apply data augmentation for training

    Returns:
        Tuple of (train_transform, val_transform)
    """

    # Normalization values (ImageNet standard)
    normalize = transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )

    if augment:
        train_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize
        ])
    else:
        train_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            normalize
        ])

    val_transform = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        normalize
    ])

    return train_transform, val_transform


def create_synthetic_dataset(
    size: int = 1000,
    img_size: int = 224,
    num_classes: int = 10,
    train_split: float = 0.8,
    augment: bool = True,
    random_seed: Optional[int] = 42
) -> Tuple[datasets.FakeData, datasets.FakeData]:
    """
    Create synthetic dataset using torchvision.datasets.FakeData

    Args:
        size: Total number of samples
        img_size: Image size (height and width)
        num_classes: Number of classes
        train_split: Fraction of data to use for training
        augment: Whether to apply data augmentation
        random_seed: Random seed for reproducibility

    Returns:
        Tuple of (train_dataset, val_dataset)
    """

    if random_seed is not None:
        torch.manual_seed(random_seed)

    # Get transforms
    train_transform, val_transform = get_transforms(img_size=img_size, augment=augment)

    print(f"ğŸ”„ Creating synthetic dataset with {size} samples...")
    print(f"ğŸ–¼ï¸ Image size: {img_size}x{img_size}")
    print(f"ğŸ·ï¸ Number of classes: {num_classes}")
    print(f"ğŸ“Š Train/Val split: {train_split:.1%}/{1-train_split:.1%}")

    # Calculate split sizes
    train_size = int(size * train_split)
    val_size = size - train_size

    # Create datasets
    train_dataset = datasets.FakeData(
        size=train_size,
        image_size=(3, img_size, img_size),
        num_classes=num_classes,
        transform=train_transform,
        random_offset=0
    )

    val_dataset = datasets.FakeData(
        size=val_size,
        image_size=(3, img_size, img_size),
        num_classes=num_classes,
        transform=val_transform,
        random_offset=train_size
    )

    print(f"âœ… Training samples: {len(train_dataset)}")
    print(f"âœ… Validation samples: {len(val_dataset)}")

    return train_dataset, val_dataset


def create_data_loaders(
    train_dataset,
    val_dataset,
    batch_size: int = 32,
    num_workers: int = 0,
    pin_memory: bool = True
) -> Tuple[DataLoader, DataLoader]:
    """
    Create data loaders for training and validation
    """
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=False
    )

    print(f"ğŸš‚ Train loader: {len(train_loader)} batches")
    print(f"ğŸšŒ Val loader: {val_loader.__len__()} batches")
    print(f"ğŸ“¦ Batch size: {batch_size}")

    return train_loader, val_loader

# Test dataset creation
print("ğŸ§ª Testing dataset creation...")
train_dataset, val_dataset = create_synthetic_dataset(
    size=500,  # Smaller for quick testing
    img_size=224,
    num_classes=10,
    train_split=0.8,
    augment=True
)

train_loader, val_loader = create_data_loaders(
    train_dataset, val_dataset, batch_size=16, num_workers=0
)

# Test a sample batch
images, labels = next(iter(train_loader))
print(f"\nğŸ” Sample batch test:")
print(f"Images shape: {images.shape}")
print(f"Labels shape: {labels.shape}")
print(f"Image range: [{images.min().item():.3f}, {images.max().item():.3f}]")
print(f"Unique labels: {torch.unique(labels).tolist()}")
print("âœ… Dataset creation successful!")

"""## ğŸ‹ï¸ 7. UtilitÄƒÈ›ile pentru Antrenament

Implementarea Trainer class È™i utilitÄƒÈ›ile pentru metrici È™i antrenament.

"""

class AverageMeter:
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def accuracy(output: torch.Tensor, target: torch.Tensor, topk: Tuple[int, ...] = (1,)) -> List[float]:
    """
    Computes the accuracy over the k top predictions

    Args:
        output: Model predictions (batch_size, num_classes)
        target: Ground truth labels (batch_size,)
        topk: Tuple of k values for top-k accuracy

    Returns:
        List of top-k accuracies
    """
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size).item())
        return res


def create_optimizer(model: nn.Module, lr: float = 1e-3, weight_decay: float = 1e-4) -> optim.Optimizer:
    """Create optimizer for the model"""
    return optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)


def create_scheduler(
    optimizer: optim.Optimizer,
    num_epochs: int,
    scheduler_type: str = 'cosine'
) -> optim.lr_scheduler._LRScheduler:
    """Create learning rate scheduler"""
    if scheduler_type == 'cosine':
        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
    elif scheduler_type == 'step':
        return optim.lr_scheduler.StepLR(optimizer, step_size=num_epochs//3, gamma=0.1)
    else:
        raise ValueError(f"Unknown scheduler type: {scheduler_type}")

# Test utility functions
print("ğŸ§ª Testing training utilities...")
dummy_output = torch.randn(16, 10)
dummy_target = torch.randint(0, 10, (16,))
acc = accuracy(dummy_output, dummy_target, topk=(1, 5))
print(f"âœ… Top-1 accuracy: {acc[0]:.2f}%")
print(f"âœ… Top-5 accuracy: {acc[1]:.2f}%")

meter = AverageMeter()
for i in range(5):
    meter.update(i * 10, 1)
print(f"âœ… Average meter test: {meter.avg:.2f}")
print("âœ… Training utilities test successful!")

class Trainer:
    """
    Training class for MambaVision model
    """
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion: nn.Module,
        optimizer: optim.Optimizer,
        scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        use_wandb: bool = True,
        save_dir: str = './checkpoints'
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        self.use_wandb = use_wandb
        self.save_dir = save_dir

        # Create save directory
        os.makedirs(save_dir, exist_ok=True)

        # Training state
        self.current_epoch = 0
        self.best_acc = 0.0
        self.train_losses = []
        self.val_losses = []
        self.val_accuracies = []

        print(f"ğŸš€ Training on device: {device}")
        print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}")

    def train_epoch(self) -> Dict[str, float]:
        """Train for one epoch"""
        self.model.train()

        losses = AverageMeter()
        top1 = AverageMeter()

        pbar = tqdm(self.train_loader, desc=f'ğŸ‹ï¸ Training Epoch {self.current_epoch + 1}')

        for batch_idx, (images, targets) in enumerate(pbar):
            images = images.to(self.device, non_blocking=True)
            targets = targets.to(self.device, non_blocking=True)

            # Forward pass
            outputs = self.model(images)
            loss = self.criterion(outputs, targets)

            # Backward pass
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # Compute accuracy
            acc1 = accuracy(outputs, targets, topk=(1,))[0]

            # Update meters
            losses.update(loss.item(), images.size(0))
            top1.update(acc1, images.size(0))

            # Update progress bar
            pbar.set_postfix({
                'Loss': f'{losses.avg:.4f}',
                'Acc@1': f'{top1.avg:.2f}%'
            })

            # Log to wandb
            if self.use_wandb and batch_idx % 10 == 0:
                try:
                    wandb.log({
                        'train/batch_loss': loss.item(),
                        'train/batch_acc': acc1,
                        'train/learning_rate': self.optimizer.param_groups[0]['lr'],
                        'epoch': self.current_epoch,
                        'batch': batch_idx
                    })
                except Exception:
                    # Ignore wandb errors if not properly initialized
                    pass

        return {
            'train_loss': losses.avg,
            'train_acc': top1.avg
        }

    def validate(self) -> Dict[str, float]:
        """Validate the model"""
        self.model.eval()

        losses = AverageMeter()
        top1 = AverageMeter()

        with torch.no_grad():
            pbar = tqdm(self.val_loader, desc='ğŸ” Validating')

            for images, targets in pbar:
                images = images.to(self.device, non_blocking=True)
                targets = targets.to(self.device, non_blocking=True)

                # Forward pass
                outputs = self.model(images)
                loss = self.criterion(outputs, targets)

                # Compute accuracy
                acc1 = accuracy(outputs, targets, topk=(1,))[0]

                # Update meters
                losses.update(loss.item(), images.size(0))
                top1.update(acc1, images.size(0))

                # Update progress bar
                pbar.set_postfix({
                    'Loss': f'{losses.avg:.4f}',
                    'Acc@1': f'{top1.avg:.2f}%'
                })

        return {
            'val_loss': losses.avg,
            'val_acc': top1.avg
        }

    def save_checkpoint(self, metrics: Dict[str, float], is_best: bool = False):
        """Save model checkpoint"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_acc': self.best_acc,
            'metrics': metrics
        }

        # Save latest checkpoint
        checkpoint_path = os.path.join(self.save_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, checkpoint_path)

        # Save best checkpoint
        if is_best:
            best_path = os.path.join(self.save_dir, 'best_checkpoint.pth')
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ New best model saved with accuracy: {self.best_acc:.2f}%")

    def train(self, num_epochs: int, resume_from: Optional[str] = None):
        """
        Main training loop
        """
        print(f"ğŸš€ Starting training for {num_epochs} epochs...")
        start_time = time.time()

        for epoch in range(self.current_epoch, num_epochs):
            self.current_epoch = epoch

            # Train for one epoch
            train_metrics = self.train_epoch()

            # Validate
            val_metrics = self.validate()

            # Update learning rate
            if self.scheduler:
                self.scheduler.step()

            # Combine metrics
            metrics = {**train_metrics, **val_metrics}

            # Check if best model
            is_best = val_metrics['val_acc'] > self.best_acc
            if is_best:
                self.best_acc = val_metrics['val_acc']

            # Save checkpoint
            self.save_checkpoint(metrics, is_best)

            # Store metrics
            self.train_losses.append(train_metrics['train_loss'])
            self.val_losses.append(val_metrics['val_loss'])
            self.val_accuracies.append(val_metrics['val_acc'])

            # Log to wandb
            if self.use_wandb:
                try:
                    wandb.log({
                        'epoch': epoch,
                        'train/epoch_loss': train_metrics['train_loss'],
                        'train/epoch_acc': train_metrics['train_acc'],
                        'val/epoch_loss': val_metrics['val_loss'],
                        'val/epoch_acc': val_metrics['val_acc'],
                        'val/best_acc': self.best_acc
                    })
                except Exception:
                    # Ignore wandb errors if not properly initialized
                    pass

            # Print epoch summary
            print(f"\nğŸ“Š Epoch {epoch + 1}/{num_epochs} Summary:")
            print(f"ğŸ‹ï¸ Train Loss: {train_metrics['train_loss']:.4f}, Train Acc: {train_metrics['train_acc']:.2f}%")
            print(f"ğŸ” Val Loss: {val_metrics['val_loss']:.4f}, Val Acc: {val_metrics['val_acc']:.2f}%")
            print(f"ğŸ† Best Val Acc: {self.best_acc:.2f}%")
            print("-" * 50)

        total_time = time.time() - start_time
        print(f"\nâœ… Training completed in {total_time:.2f} seconds")
        print(f"ğŸ† Best validation accuracy: {self.best_acc:.2f}%")

        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'val_accuracies': self.val_accuracies,
            'best_acc': self.best_acc
        }

print("âœ… Trainer class defined successfully!")

"""## ğŸ“ˆ 8. UtilitÄƒÈ›ile pentru Vizualizare

FuncÈ›ii pentru plot-uri È™i vizualizÄƒri ale rezultatelor.

"""

def plot_training_curves(metrics: Dict[str, Any], save_path: str = 'training_curves.png'):
    """Plot training curves"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    epochs = range(1, len(metrics['train_losses']) + 1)

    # Plot losses
    ax1.plot(epochs, metrics['train_losses'], 'b-', label='Train Loss', linewidth=2)
    ax1.plot(epochs, metrics['val_losses'], 'r-', label='Val Loss', linewidth=2)
    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot accuracy
    ax2.plot(epochs, metrics['val_accuracies'], 'g-', label='Val Accuracy', linewidth=2)
    ax2.axhline(y=metrics['best_acc'], color='r', linestyle='--',
                label=f'Best: {metrics["best_acc"]:.2f}%', linewidth=2)
    ax2.set_title('Validation Accuracy', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

    print(f"ğŸ“Š Training curves saved to: {save_path}")


def visualize_model_architecture(model: nn.Module, input_shape: tuple, save_path: str = 'model_architecture.png'):
    """Visualize model architecture using torchview"""
    try:
        from torchview import draw_graph

        print("ğŸ—ï¸ Generating model visualization...")

        model_graph = draw_graph(
            model,
            input_size=input_shape,
            save_graph=True,
            filename=save_path.replace('.png', ''),
            device='cpu'
        )

        print(f"âœ… Model architecture saved to: {save_path}")
        return True

    except ImportError:
        print("âŒ torchview not available. Install with: pip install torchview")
        return False
    except Exception as e:
        print(f"âŒ Error generating model visualization: {e}")
        return False


def visualize_sample_data(train_loader: DataLoader, num_samples: int = 8):
    """Visualize sample data from the dataset"""
    # Get a batch of data
    images, labels = next(iter(train_loader))

    # Denormalize images for display
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    images_denorm = images * std + mean
    images_denorm = torch.clamp(images_denorm, 0, 1)

    # Plot samples
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))
    axes = axes.flatten()

    for i in range(num_samples):
        img = images_denorm[i].permute(1, 2, 0)
        axes[i].imshow(img)
        axes[i].set_title(f'Label: {labels[i].item()}', fontweight='bold')
        axes[i].axis('off')

    plt.suptitle('Sample Dataset Images', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

    print(f"ğŸ–¼ï¸ Sample batch: {images.shape}, Labels: {labels[:num_samples].tolist()}")


def set_seed(seed: int):
    """Set random seed for reproducibility"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def get_device(device_arg: str) -> str:
    """Get device to use for training"""
    if device_arg == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = device_arg

    if device == 'cuda' and not torch.cuda.is_available():
        print("âŒ CUDA not available, falling back to CPU")
        device = 'cpu'

    return device

print("âœ… Visualization utilities defined successfully!")

"""## âš™ï¸ 9. ConfiguraÈ›ia pentru Antrenament

Setarea parametrilor È™i configuraÈ›iei pentru experimentul de antrenament.

"""

# Training configuration
config = {
    # Model parameters
    'model_size': 'tiny',  # 'tiny' or 'small'
    'num_classes': 10,
    'img_size': 224,

    # Dataset parameters
    'dataset_size': 1000,
    'train_split': 0.8,
    'augment': True,

    # Training parameters
    'batch_size': 32,
    'epochs': 50,
    'lr': 1e-3,
    'weight_decay': 1e-4,
    'scheduler': 'cosine',

    # System parameters
    'num_workers': 0,
    'seed': 42,

    # Logging and saving
    'use_wandb': True,  # Set to False if you don't want to use wandb
    'wandb_project': 'mambavision-training',
    'save_dir': './checkpoints',
    'visualize': True,
}

print("ğŸ”§ Training configuration:")
print("=" * 50)
for key, value in config.items():
    print(f"  {key:15}: {value}")
print("=" * 50)

# Set seed for reproducibility
set_seed(config['seed'])
print(f"ğŸŒ± Random seed set to: {config['seed']}")

"""## ğŸŒ 10. IniÈ›ializarea Wandb (OpÈ›ional)

Configurarea Weights & Biases pentru tracking experimente.

"""

# Initialize wandb (optional)
if config['use_wandb']:
    try:
        # Pentru prima rulare, s-ar putea sÄƒ trebuiascÄƒ sÄƒ te autentifici
        # wandb.login()

        wandb.init(
            project=config['wandb_project'],
            config=config,
            name=f"mambavision-{config['model_size']}-{config['epochs']}epochs"
        )
        print("âœ… Wandb initialized successfully")
        print(f"ğŸ“Š View your experiment: {wandb.run.url}")
    except Exception as e:
        print(f"âŒ Failed to initialize wandb: {e}")
        print("ğŸ”„ Continuing without wandb logging...")
        config['use_wandb'] = False
else:
    print("ğŸ“´ Wandb logging disabled")

print(f"ğŸ¯ Experiment tracking: {'Enabled' if config['use_wandb'] else 'Disabled'}")

"""## ğŸš€ 11. Pipeline Principal de Antrenament

Punerea Ã®mpreunÄƒ a tuturor componentelor pentru antrenamentul complet.

"""

print("=" * 60)
print("ğŸ¯ MambaVision Training Pipeline")
print("=" * 60)

# 1. Create model
print(f"\nğŸ—ï¸ 1. Creating {config['model_size']} MambaVision model...")
if config['model_size'] == 'tiny':
    model = create_mambavision_tiny(num_classes=config['num_classes'], img_size=config['img_size'])
else:
    model = create_mambavision_small(num_classes=config['num_classes'], img_size=config['img_size'])

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"ğŸ“Š Total parameters: {total_params:,}")
print(f"ğŸ“Š Trainable parameters: {trainable_params:,}")

# 2. Visualize model architecture (optional)
if config['visualize']:
    print(f"\nğŸ¨ 2. Visualizing model architecture...")
    success = visualize_model_architecture(
        model,
        input_shape=(config['batch_size'], 3, config['img_size'], config['img_size']),
        save_path='model_architecture.png'
    )
    if not success:
        print("âš ï¸ Model visualization skipped")

# 3. Create dataset and data loaders
print(f"\nğŸ“Š 3. Creating dataset and data loaders...")
train_dataset, val_dataset = create_synthetic_dataset(
    size=config['dataset_size'],
    img_size=config['img_size'],
    num_classes=config['num_classes'],
    train_split=config['train_split'],
    augment=config['augment'],
    random_seed=config['seed']
)

train_loader, val_loader = create_data_loaders(
    train_dataset,
    val_dataset,
    batch_size=config['batch_size'],
    num_workers=config['num_workers'],
    pin_memory=device == 'cuda'
)

# 4. Visualize sample data
print(f"\nğŸ–¼ï¸ 4. Visualizing sample data...")
visualize_sample_data(train_loader, num_samples=8)

# 5. Setup training components
print(f"\nâš™ï¸ 5. Setting up training components...")
criterion = nn.CrossEntropyLoss()
optimizer = create_optimizer(model, lr=config['lr'], weight_decay=config['weight_decay'])
scheduler = create_scheduler(optimizer, config['epochs'], config['scheduler'])

print(f"ğŸ“ Loss function: {criterion.__class__.__name__}")
print(f"ğŸ“ Optimizer: {optimizer.__class__.__name__}")
print(f"ğŸ“ Scheduler: {scheduler.__class__.__name__}")

# 6. Create trainer
print(f"\nğŸ‹ï¸ 6. Creating trainer...")
trainer = Trainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    device=device,
    use_wandb=config['use_wandb'],
    save_dir=config['save_dir']
)

print("âœ… All components ready for training!")

"""## ğŸ¯ 12. Rularea Antrenamentului

Antrenamentul efectiv al modelului MambaVision.

"""

# 7. Start training
print(f"\nğŸš€ 7. Starting training for {config['epochs']} epochs...")
print("=" * 60)

training_metrics = trainer.train(
    num_epochs=config['epochs']
)

print("=" * 60)
print("ğŸ‰ Training completed!")

"""## ğŸ“Š 13. Analizarea Rezultatelor

Vizualizarea È™i analizarea rezultatelor antrenamentului.

"""

# 8. Plot training curves
print(f"\nğŸ“ˆ 8. Generating training curves...")
plot_training_curves(training_metrics, 'training_curves.png')

# 9. Final results summary
print(f"\nğŸ† 9. Final Results Summary:")
print("=" * 50)
print(f"ğŸ¥‡ Best validation accuracy: {training_metrics['best_acc']:.2f}%")
print(f"ğŸ“‰ Final training loss: {training_metrics['train_losses'][-1]:.4f}")
print(f"ğŸ“‰ Final validation loss: {training_metrics['val_losses'][-1]:.4f}")
print(f"ğŸ’¾ Checkpoints saved to: {config['save_dir']}")

# 10. Log final metrics to wandb
if config['use_wandb']:
    try:
        wandb.log({
            'final/best_acc': training_metrics['best_acc'],
            'final/final_train_loss': training_metrics['train_losses'][-1],
            'final/final_val_loss': training_metrics['val_losses'][-1]
        })

        # Log training curves as images
        if os.path.exists('training_curves.png'):
            wandb.log({"training_curves": wandb.Image('training_curves.png')})

        if os.path.exists('model_architecture.png'):
            wandb.log({"model_architecture": wandb.Image('model_architecture.png')})
    except Exception:
        # Ignore wandb errors if not properly initialized
        print("âš ï¸ Wandb logging skipped due to initialization issues")

print("=" * 50)
print("ğŸ‰ Training pipeline completed successfully!")

"""## ğŸ§ª 14. Testarea Modelului Final

Testarea modelului antrenat È™i demonstrarea inferenÈ›ei.

"""

# 10. Test the trained model
print("\nğŸ§ª 10. Testing the trained model...")

# Load best checkpoint
best_checkpoint_path = os.path.join(config['save_dir'], 'best_checkpoint.pth')
if os.path.exists(best_checkpoint_path):
    checkpoint = torch.load(best_checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… Loaded best model with accuracy: {checkpoint['best_acc']:.2f}%")
else:
    print("âš ï¸ No best checkpoint found, using current model state")

# Test inference
model.eval()
test_images, test_labels = next(iter(val_loader))
test_images = test_images.to(device)
test_labels = test_labels.to(device)

with torch.no_grad():
    outputs = model(test_images)
    _, predicted = torch.max(outputs, 1)

    # Calculate accuracy for this batch
    batch_accuracy = (predicted == test_labels).float().mean().item() * 100

    print(f"\nğŸ” Test batch results:")
    print(f"ğŸ“Š Batch accuracy: {batch_accuracy:.2f}%")
    print(f"ğŸ¯ Predictions: {predicted[:8].cpu().tolist()}")
    print(f"âœ… Ground truth: {test_labels[:8].cpu().tolist()}")

# Show confidence scores for first few samples
probabilities = F.softmax(outputs[:5], dim=1)
confidences, pred_classes = torch.max(probabilities, 1)

print(f"\nğŸ¯ Confidence scores for first 5 samples:")
for i in range(5):
    confidence_percent = confidences[i].item() * 100
    print(f"  Sample {i+1}: Class {pred_classes[i].item()} with {confidence_percent:.1f}% confidence")

"""## ğŸ‰ 15. Sumar Final È™i PaÈ™i UrmÄƒtori

Ãnchiderea experimentului È™i sugestii pentru continuare.

"""

# Finish wandb run
if config['use_wandb']:
    try:
        wandb.finish()
        print("ğŸŒ Wandb run finished")
    except Exception:
        print("âš ï¸ Wandb finish skipped due to initialization issues")

# Print final summary
print("\n" + "=" * 60)
print("ğŸ‰ MambaVision Training Complete!")
print("=" * 60)
print(f"âœ… Model: {config['model_size']} MambaVision ({total_params:,} parameters)")
print(f"âœ… Dataset: {config['dataset_size']} synthetic samples")
print(f"âœ… Training: {config['epochs']} epochs completed")
print(f"âœ… Best accuracy: {training_metrics['best_acc']:.2f}%")
print(f"âœ… Checkpoints saved to: {config['save_dir']}")
print("\nğŸš€ Ready for further experimentation!")

print("\nğŸ“š Next steps:")
print("- Experiment with different model sizes (tiny/small)")
print("- Try different hyperparameters (learning rate, batch size, etc.)")
print("- Test on real datasets (CIFAR-10, ImageNet, etc.)")
print("- Compare with other vision models")
print("- Analyze model performance and efficiency")
print("- Implement attention visualization")
print("- Add more sophisticated data augmentation")

print(f"\nğŸ¯ How to load and use this model:")
print(f"```python")
print(f"# Load the trained model")
print(f"checkpoint = torch.load('{final_model_path}')")
print(f"model = create_mambavision_{config['model_size']}(num_classes={config['num_classes']})")
print(f"model.load_state_dict(checkpoint['model_state_dict'])")
print(f"model.eval()")
print(f"")
print(f"# Use for inference")
print(f"with torch.no_grad():")
print(f"    predictions = model(your_images)")
print(f"```")

print("\nğŸ™ Thank you for using MambaVision!")
print("=" * 60)

# Install torchview for model visualization
print("ğŸ“¦ Installing torchview and graphviz...")

# Install packages
import subprocess
import sys

try:
    # Install torchview
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torchview', '--quiet'])
    print("âœ… torchview installed successfully!")

    # Try to install graphviz (pentru vizualizÄƒri mai avansate)
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'graphviz', '--quiet'])
        print("âœ… graphviz installed successfully!")
    except:
        print("âš ï¸ graphviz could not be installed, but torchview will still work with basic features")

except Exception as e:
    print(f"âŒ Installation failed: {e}")
    print("ğŸ’¡ You can install manually with: pip install torchview graphviz")

print("\nğŸ¯ Ready for model visualization!")

# Simple TorchView visualization setup
try:
    from torchview import draw_graph
    print("âœ… TorchView imported successfully!")
    torchview_available = True

except ImportError as e:
    print(f"âŒ Could not import torchview: {e}")
    print("ğŸ’¡ Install with: pip install torchview")
    torchview_available = False

# Simple Model Visualization
if torchview_available:
    print("ğŸ¨ Creating MambaVision architecture visualization...")

    try:
        # Use existing model or create new one
        model_to_viz = create_mambavision_tiny(num_classes=10)
        model_to_viz.eval()

        # Simple visualization
        model_graph = draw_graph(
            model_to_viz,
            input_size=(1, 3, 224, 224),
            depth=3,
            device='cpu',
            hide_module_functions=True,
            hide_inner_tensors=True,
            show_shapes=True,
            save_graph=True,
            filename='mambavision_architecture'
        )

        print("âœ… Model visualization created!")
        print("ğŸ“ Saved as 'mambavision_architecture.png'")

        # Display
        display(model_graph.visual_graph)

    except Exception as e:
        print(f"âŒ Error: {e}")
        print("ğŸ’¡ Try: pip install graphviz and install system graphviz")

else:
    print("âš ï¸ Install torchview first: pip install torchview")
